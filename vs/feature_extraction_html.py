# feature_extraction_html.py
#
# Read a list of HTML files and count HTML tag occurrences.
#
#
# Input: list of HTML file names.
#        html-tags.txt
#
# Output: sorted-html-features.csv
#         row format = [ file_name, [list html tags...] ]
#
# Author: Derek Chadwick
# Date  : 05/09/2016
#
# TODO: all of the things


from multiprocessing import Pool
import os
from csv import writer
import numpy as np
import pandas as pd
import math
import scipy.misc
import array
import time as tm
import re




def get_html_tags(file_name):
    # Get the list of html tags.
    html_tags = []
    fip = open(file_name, 'r')
    for tag in lines:
        tag = tag.rstrip()
        html_tags.append(tag)
        
        
    return html_tags


def count_html_tags(content, tag_list, klen):
    
    tag_values = [0] * klen
    
    for row in content:
        for i in range(klen):
            if tag_list[i] in row:
                tag_values[i] += 1
                break
                
    return tag_values



def extract_html_features(multi_parameters):
    # 1. Get the feature file and tag list file
    # 2. Create an array of tag values.
    # 3. Iterate throught the html file list and count the occurrence of the tags in each file.

    pid = os.getpid()
    feature_file = 'data/' + str(pid) + "-" + multi_parameters.out_file  
    tag_file = 'data/' + multi_parameters.token_file
    html_files = multi_parameters.file_list
    
    print('Process id: {:d} - Feature file: {:s} - Tag file: {:s}'.format(pid, feature_file, tag_file))

    hdr_pd = pd.read_csv(tag_file)
    tag_list = list(hdr_pd['tag_name'])
    tlen = len(tag_list)
    ftot = len(html_files)
    
    feature_counts = []
    with open(feature_file, 'w') as f:

        fw = writer(f)
        fw.writerow(['file_name'] + tokens)
        
        for idx, fname in enumerate(pdf_files):
            
            fasm = open(fname, 'r')
            content = fasm.readlines()
            fasm.close()

            #print("Debug in -> {:s}".format(fname))
            
            #fname = fname[fname.find("_")+1:] 
            # Remove VirusShare_ from the start of the file name.
            
            keyword_vals = count_pdf_keywords(content, tokens, tlen)
            
            #feature_counts.append([fname[0:fname.find('.pe.txt')]] + keyword_vals)   
            feature_counts.append([fname] + keyword_vals)
            
            # Writing rows after every 10 files processed
            if (idx+1) % 10 == 0:
                print("{:d} - {:d} of {:d} files processed.".format(pid, idx + 1, ftot))
                fw.writerows(feature_counts)
                feature_counts = []
                
            #print("Debug out -> {:s}".format(fname))

        # Writing remaining features
        if len(feature_counts) > 0:
            fw.writerows(feature_counts)
            feature_counts = []

    print("{:d} Completed processing {:d} PDF files.".format(pid, ftot))
                      
    return



class Multi_Params(object):
    def __init__(self, outfile="", tokenfile="", filelist=[]):
        self.out_file = outfile
        self.token_file = tokenfile
        self.file_list = filelist
        
        
        
        
# Start of Script

target_dir = "/opt/vs//"
out_file = "html-features-vs251.csv"
html_tag_file = "html-tags.txt"



# Get a list of HTML files in the file set.
html_list = []
fip = open('data/html-file-list-vs251.txt', 'r')
for line in in_lines:
    line = line.rstrip()
    html_list.append(line)
    
    
print("Got {:d} HTML files.".format(len(html_list)))

mp1 = Multi_Params(out_file, html_tag_file, html_list)

extract_html_features(mp1)


# End of Script
