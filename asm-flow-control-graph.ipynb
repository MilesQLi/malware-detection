{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Flow Control Graphs From Intel x86/AMD 64 Assembly\n",
    "       Parse a directory of .asm files and construct IDA Pro style flow control graphs using code\n",
    "       blocks as vertices and jmp/call instructions as directed edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graph as gra # http://www.python-course.eu/graphs_python.php\n",
    "import os\n",
    "from csv import writer\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opcodes = ['call','int','ja','jb','jc','je','jg','jge','jl','jle','jmp','jna','jnb','jnl','jno','jnp','jns','jnz','jo','jp','jz']\n",
    "blocks = ['sub_', 'loc_', 'locret_']\n",
    "#blocks = ['loc_','locret_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "# Now divide the train files into four groups for multiprocessing\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "quart = len(tfiles)/4\n",
    "train1 = tfiles[:quart]\n",
    "train2 = tfiles[quart:(2*quart)]\n",
    "train3 = tfiles[(2*quart):(3*quart)]\n",
    "train4 = tfiles[(3*quart):]\n",
    "print(len(tfiles), quart, (len(train1)+len(train2)+len(train3)+len(train4)))\n",
    "trains = [train1, train2, train3, train4]\n",
    "p = Pool(4)\n",
    "p.map(extract_graph, trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TESTING\n",
    "# Now divide the test files into four groups for multiprocessing\n",
    "ext_drive = '/opt/kaggle/test/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "quart = len(tfiles)/4\n",
    "test1 = tfiles[:quart]\n",
    "test2 = tfiles[quart:(2*quart)]\n",
    "test3 = tfiles[(2*quart):(3*quart)]\n",
    "test4 = tfiles[(3*quart):]\n",
    "print(len(tfiles), quart, (len(test1)+len(test2)+len(test3)+len(test4)))\n",
    "tests = [test1, test2, test3, test4]\n",
    "p = Pool(4)\n",
    "p.map(extract_graph, tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_flow_control_graph(lines):\n",
    "    vertex = '.program_entry_point' # this is the root node, corresponds to the program entry point not C main().\n",
    "    vertex_count = 1\n",
    "    edge_count = 0\n",
    "    cfgraph = gra.Graph()\n",
    "    cfgraph.add_vertex(vertex)\n",
    "    \n",
    "    for row in lines:\n",
    "      row = row.rstrip('\\r\\n')  # get rid of newlines they are annoying.\n",
    "      if ';' in row:\n",
    "        row = row.split(';')[0] # get rid of comments they are annoying.\n",
    "        #print(row)\n",
    "      \n",
    "      # get rid of all these things they are annoying.\n",
    "      row = row.replace('short',' ')\n",
    "      row = row.replace('ds:',' ')\n",
    "      row = row.replace('dword',' ')\n",
    "      row = row.replace('ptr',' ').replace(':',' ').replace(',',' ') #.replace('??',' ')\n",
    "      row = row.replace('@','').replace('?','')\n",
    "      parts = row.split() # tokenize code line\n",
    "        \n",
    "      parts_len = len(parts)\n",
    "    \n",
    "      if (parts_len < 3): # this is just a comment line, do NOT change this!!!\n",
    "        continue\n",
    "        \n",
    "      if (parts_len > 3 ):\n",
    "        if (parts[3] == 'endp'): # skip procedure end labels\n",
    "            continue\n",
    "        if (parts[3] == 'proc'): # check for procedures not labelled sub_????\n",
    "            vertex = parts[2]\n",
    "            cfgraph.add_vertex(vertex)\n",
    "            vertex_count += 1\n",
    "            continue\n",
    "            \n",
    "      # check for subroutines and block labels\n",
    "      # block and subroutine labels are always after the .text HHHHHHHH relative address\n",
    "      for block in blocks:\n",
    "          token = parts[2]  \n",
    "          idx = token.find(block)\n",
    "          if (idx == 0): # add new vertex to the graph, we are now in a new subroutine or code block\n",
    "              vertex = token\n",
    "              cfgraph.add_vertex(vertex)\n",
    "              # print(\"Vertex: \" + vertex)\n",
    "              vertex_count += 1\n",
    "              break\n",
    "                              \n",
    "\n",
    "      # now check for edge opcode    \n",
    "      for opcode in opcodes: # check the line for a new edge\n",
    "          if opcode in parts:\n",
    "              # Extract desination address/function name/interrupt number as the directed edge.\n",
    "              idx = parts.index(opcode)     \n",
    "              next_vertex = parts[idx + 1]\n",
    "              cfgraph.add_edge(vertex, next_vertex)\n",
    "              # print(\"Edge: \" + vertex + \" \" + parts[idx] + \" \" + edge)\n",
    "              break\n",
    "\n",
    "    print(\"Vertex Count: {:d}\".format(vertex_count))\n",
    "    \n",
    "    return cfgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(str.find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(str.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_flow_control_graphs(tfiles):\n",
    "    byte_files = [i for i in tfiles if '.asm' in i]\n",
    "    ftot = len(byte_files)\n",
    "    \n",
    "    pid = os.getpid()\n",
    "    print('Process id:', pid)\n",
    "    feature_file = 'data/' + str(pid) + '-malware-flow-control-graph.csv'  \n",
    "    print('Flow Control Graph file:', feature_file)\n",
    "    \n",
    "    graph_lines = []\n",
    "    with open(feature_file, 'w') as f:\n",
    "        # write the column names for the csv file\n",
    "        fw = writer(f)\n",
    "        # colnames = ['filename'] + ['entropy'] + ['filesize']\n",
    "        # fw.writerow(colnames)\n",
    "        \n",
    "        # Now iterate through the file list and extract the graph from each file.\n",
    "        for idx, fname in enumerate(byte_files):\n",
    "            fasm = open(ext_drive + fname, 'r', errors='ignore')\n",
    "            #filesize = os.path.getsize(ext_drive + fname)\n",
    "            lines = fasm.readlines()\n",
    "            \n",
    "            flow_control_graph = construct_flow_control_graph(lines)\n",
    "\n",
    "            graph_lines.append([fname[:fname.find('.asm')]] + [str(flow_control_graph.to_str_multi_line_sorted())])   \n",
    "            \n",
    "            del(flow_control_graph)\n",
    "            \n",
    "            # Print progress\n",
    "            if (idx+1) % 10 == 0:\n",
    "              print(pid, idx + 1, 'of', ftot, 'files processed.')\n",
    "              fw.writerows(graph_lines)\n",
    "              feature_counts = []\n",
    "                \n",
    "        # Write remaining files\n",
    "        if len(graph_lines) > 0:\n",
    "            fw.writerows(graph_lines)\n",
    "            graph_lines = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert Flow Control Graphs To Feature Vectors\n",
    "       Since determining graph isomorphisms is NP-Complete, convert the graphs to feature vectors and\n",
    "       use chi-squared tests to reduce the number features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Generate Call Graphs From Intel x86/AMD 64 Assembly\n",
    "       Parse a directory of .asm files and construct call graphs using subroutines\n",
    "       as vertices and call instructions as directed edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "call_opcodes = ['call','int']\n",
    "call_blocks = ['sub_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_call_graph(lines):\n",
    "    vertex = '.program_entry_point' # this is the root node, corresponds to the program entry point not C main().\n",
    "    vertex_count = 1\n",
    "    edge_count = 0\n",
    "    cfgraph = gra.Graph()\n",
    "    cfgraph.add_vertex(vertex)\n",
    "    \n",
    "    for row in lines:\n",
    "      row = row.rstrip('\\r\\n')  # get rid of newlines they are annoying.\n",
    "      if ';' in row:\n",
    "        row = row.split(';')[0] # get rid of comments they are annoying.\n",
    "        #print(row)\n",
    "      \n",
    "      # get rid of all these things they are annoying.\n",
    "      row = row.replace('short',' ')\n",
    "      row = row.replace('ds:',' ')\n",
    "      row = row.replace('dword',' ')\n",
    "      row = row.replace('ptr',' ').replace(':',' ').replace(',',' ') #.replace('??',' ')\n",
    "      row = row.replace('@','').replace('?','')\n",
    "      parts = row.split() # tokenize code line\n",
    "        \n",
    "      if (len(parts) < 4): # this is just a comment line\n",
    "        continue\n",
    "        \n",
    "      if (parts[3] == 'endp'):\n",
    "        continue\n",
    "        \n",
    "      # check for subroutines and block labels\n",
    "      # block and subroutine labels are always after the .text HHHHHHHH relative address\n",
    "      for block in call_blocks:\n",
    "          token = parts[2]  \n",
    "          idx = token.find(block)\n",
    "          if ((idx == 0) or (parts[3] == 'proc')):\n",
    "              # add new vertex to the graph, we are now in a new subroutine\n",
    "              vertex = token\n",
    "              cfgraph.add_vertex(vertex)\n",
    "              # print(\"Vertex: \" + vertex)\n",
    "              vertex_count += 1\n",
    "              break\n",
    "\n",
    "      # now check for edge opcode    \n",
    "      for opcode in call_opcodes: # check the line for a new edge\n",
    "          if opcode in parts:\n",
    "              # Extract desination address/function name/interrupt number as the directed edge.\n",
    "              idx = parts.index(opcode)     \n",
    "              next_vertex = parts[idx + 1]\n",
    "              cfgraph.add_edge(vertex, next_vertex)\n",
    "              # print(\"Edge: \" + vertex + \" \" + parts[idx] + \" \" + edge)\n",
    "              break\n",
    "\n",
    "    print(\"Vertex Count: {:d}\".format(vertex_count))\n",
    "    \n",
    "    return cfgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_call_graphs(tfiles):\n",
    "    byte_files = [i for i in tfiles if '.asm' in i]\n",
    "    ftot = len(byte_files)\n",
    "    \n",
    "    pid = os.getpid()\n",
    "    print('Process id:', pid)\n",
    "    feature_file = 'data/' + str(pid) + '-malware-call-graph.csv'  \n",
    "    print('Graph file:', feature_file)\n",
    "    \n",
    "    graph_lines = []\n",
    "    with open(feature_file, 'w') as f:\n",
    "        # write the column names for the csv file\n",
    "        fw = writer(f)\n",
    "        # colnames = ['filename'] + ['entropy'] + ['filesize']\n",
    "        # fw.writerow(colnames)\n",
    "        \n",
    "        # Now iterate through the file list and extract the graph from each file.\n",
    "        for idx, fname in enumerate(byte_files):\n",
    "            fasm = open(ext_drive + fname, 'r', errors='ignore')\n",
    "            #filesize = os.path.getsize(ext_drive + fname)\n",
    "            lines = fasm.readlines()\n",
    "            \n",
    "            call_graph = construct_call_graph(lines)\n",
    "\n",
    "            graph_lines.append([fname[:fname.find('.asm')]] + [str(call_graph.to_str_multi_line_sorted())])   \n",
    "            \n",
    "            del(call_graph) # for some reason new graphs get appended to the previous graphs???\n",
    "            \n",
    "            # Print progress\n",
    "            if (idx+1) % 10 == 0:\n",
    "              print(pid, idx + 1, 'of', ftot, 'files processed.')\n",
    "              fw.writerows(graph_lines)\n",
    "              feature_counts = []\n",
    "                \n",
    "        # Write remaining files\n",
    "        if len(graph_lines) > 0:\n",
    "            fw.writerows(graph_lines)\n",
    "            graph_lines = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Test Code Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id: 4845\n",
      "Graph file: data/4845-malware-graph.csv\n",
      "Vertex Count: 1103\n",
      "Vertex Count: 6418\n"
     ]
    }
   ],
   "source": [
    "# Test graph generation\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = ['0A32eTdBKayjCWhZqDOQ.asm', '1aAwe4J9VHrsq8uEoZhf.asm']\n",
    "extract_graph(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id: 17216\n",
      "Graph file: data/17216-malware-graph.csv\n",
      "Vertex Count: 1103\n",
      "Vertex Count: 180\n"
     ]
    }
   ],
   "source": [
    "# Test graph generation\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = ['0A32eTdBKayjCWhZqDOQ.asm', '0ACDbR5M3ZhBJajygTuf.asm']\n",
    "extract_graph(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id: 21155\n",
      "Flow Control Graph file: data/21155-malware-flow-control-graph.csv\n",
      "Vertex Count: 179\n"
     ]
    }
   ],
   "source": [
    "# Test graph generation\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = ['0ACDbR5M3ZhBJajygTuf.asm']\n",
    "extract_flow_control_graphs(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id: 17385\n",
      "Graph file: data/17385-malware-call-graph.csv\n",
      "Vertex Count: 179\n",
      "Vertex Count: 5\n"
     ]
    }
   ],
   "source": [
    "# Test call graph generation\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = ['0A32eTdBKayjCWhZqDOQ.asm', '0ACDbR5M3ZhBJajygTuf.asm']\n",
    "extract_call_graphs(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test call graph generation\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = ['0A32eTdBKayjCWhZqDOQ.asm', '0ACDbR5M3ZhBJajygTuf.asm']\n",
    "extract_call_graphs(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id: 20756\n",
      "Graph file: data/20756-malware-call-graph.csv\n",
      "Vertex Count: 90\n",
      "Vertex Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Test call graph generation\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = ['0A32eTdBKayjCWhZqDOQ.asm', '0ACDbR5M3ZhBJajygTuf.asm']\n",
    "extract_call_graphs(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id: 20756\n",
      "Graph file: data/20756-malware-call-graph.csv\n",
      "Vertex Count: 90\n",
      "Vertex Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Test call graph generation\n",
    "ext_drive = '/opt/kaggle/train/'\n",
    "tfiles = ['0A32eTdBKayjCWhZqDOQ.asm', '0ACDbR5M3ZhBJajygTuf.asm']\n",
    "extract_call_graphs(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cfgraph.vertices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fasm = open('/opt/kaggle/train/1aAwe4J9VHrsq8uEoZhf.asm', 'r', errors='ignore')\n",
    "lines = fasm.readlines()\n",
    "parse_asm_code(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fasm = open('/opt/kaggle/train/0A32eTdBKayjCWhZqDOQ.asm', 'r', errors='ignore')\n",
    "lines = fasm.readlines()\n",
    "cfgraph = parse_asm_code(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bar': 2, 'foo': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "a = {'foo': 1, 'bar': 2}\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bar', 2), ('foo', 1)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'foo': 1, 'bar': 2}\n",
    "b = OrderedDict(sorted(a.items()))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 10]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDic={10: 'b', 3:'a', 5:'c'}\n",
    "sorted_list=sorted(myDic.keys())\n",
    "sorted_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
