# generate_call_graphs_pe_asm.py
#
# Read a list of PE ASM files generated by IDA Pro and generate 
# Graphviz DOT style directed graphs for the function calls in each ASM file.
#
# Input : List of ASM code files generated by IDA Pro or objdump.
#
# Output: sorted-call-graphs.gv
#         row format = dirgraph FILENAME { [ calling_function_name -> [ called_function_name1 ; ... ] ] } 
#
#
#
# Author: Derek Chadwick
# Date  : 27/09/2016
#
# TODO: optimise and many many things

from multiprocessing import Pool
import os
from csv import writer
import numpy as np
import pandas as pd
import math
import scipy.misc
import array
import time as tm
import re
import subprocess as sub
import graph as gra


call_opcodes = ['call','int']
call_blocks = ['sub_']




def construct_call_graph(lines):
    vertex = '.program_entry_point' # this is the root node, corresponds to the program entry point not C main().
    vertex_count = 1
    edge_count = 0
    cfgraph = gra.Graph()
    cfgraph.add_vertex(vertex)
    
    for row in lines:
        row = row.rstrip('\r\n')  # get rid of newlines they are annoying.
        if ';' in row:
            row = row.split(';')[0] # get rid of comments they are annoying.
            #print(row)
      
        # get rid of all these things they are annoying.
        row = row.replace('short','').replace('ds:',' ')
        row = row.replace('dword','').replace('near','')
        row = row.replace('ptr','').replace(':',' ').replace(',',' ')
        row = row.replace('@','').replace('?','')
        parts = row.split() # tokenize code line
        
        if (len(parts) < 4): # this is just a comment line
            continue
        
        if (parts[3] == 'endp'): # ignore subroutine end labels
            continue
        
        # check for subroutines and block labels
        # block and subroutine labels are always after the .text HHHHHHHH relative address
        for block in call_blocks:
            token = parts[2]  
            idx = token.find(block)
            if ((idx == 0) or (parts[3] == 'proc')):
                # add new vertex to the graph, we are now in a new subroutine
                vertex = token
                cfgraph.add_vertex(vertex)
                # print("Vertex: " + vertex)
                vertex_count += 1
                break

        # now check for edge opcode    
        for opcode in call_opcodes: # check the line for a new edge
            if opcode in parts:
                # Extract desination address/function name/interrupt number as the directed edge.
                idx = parts.index(opcode)
                edge_count += 1
                if ((idx + 1) < len(parts)): # in a few ASM files there is no operand, disassembly error?
                    next_vertex = parts[idx + 1]
                else:
                    next_vertex = "none"
                cfgraph.add_edge(vertex, next_vertex)
                # print("Edge: " + vertex + " " + parts[idx] + " " + edge)
                break

    # print("Vertex Count: {:d}".format(vertex_count))
    
    return cfgraph


def extract_call_graphs(tfiles):
    asm_files = [i for i in tfiles if '.asm' in i]
    ftot = len(asm_files)
    
    pid = os.getpid()
    print('Process id:', pid)
    feature_file = 'data/' + str(pid) + '-malware-call-graph-features.csv'  
    print('Graph Feature file:', feature_file)
    
    graph_lines = []
    graph_features = []
    graph_file = open('data/' + str(pid) + '-malware-call-graphs.gv', 'w') # write as a graphviz DOT format file
    with open(feature_file, 'w') as f:
        # write the column names for the csv file
        fw = writer(f)
        #colnames = ['filename','vertex_count','edge_count','delta_max','density','diameter']
        colnames = ['filename','vertex_count','edge_count','delta_max','density']
        fw.writerow(colnames)
        
        # Now iterate through the file list and extract the call graph from each file.
        for idx, fname in enumerate(asm_files):
            fasm = open(ext_drive + fname, 'r', errors='ignore')
            
            lines = fasm.readlines()
            
            call_graph = construct_call_graph(lines)
            cgvc = call_graph.n_vertices()
            cgec = call_graph.n_edges()
            cgdm = call_graph.delta_max()
            cgde = call_graph.density()
            # cdia = call_graph.diameter() this is constantly problematic !!!
            graph_features.append([fname[:fname.find('.asm')]] + [cgvc, cgec, cgdm, cgde])
            call_graph.set_graph_name(fname[:fname.find('.asm')])
            # graph_lines.append(call_graph.to_str('multinoleaf')) 
            graph_lines.append(call_graph.to_str('singlenoleaf'))
            
            del(call_graph) # for some reason new graphs get appended to the previous graphs if not deleted???
            
            # Print progress
            if (idx + 1) % 10 == 0:
                print(pid, idx + 1, 'of', ftot, 'files processed.')
                fw.writerows(graph_features)
                graph_file.writelines(graph_lines)
                graph_features = []
                graph_lines = []
                
        # Write remaining files
        if len(graph_lines) > 0:
            fw.writerows(graph_features)
            graph_file.writelines(graph_lines)
            graph_features = []
            graph_lines = []

    graph_file.close()
    
    print('Process id: {:d} finished.'.format(pid))

    
class Multi_Params(object):
    def __init__(self, featurefile="", tempfile="", extdrive="", filelist=[]):
        self.feature_file = featurefile
        self.temp_file = tempfile
        self.ext_drive = extdrive
        self.file_list = filelist


        
# Start of Script

# Divide the train files into four groups for multiprocessing.

# TODO: add command line arguments to specify file names.

#out_file = 'pe-asm-features-apt.csv'
#temp_file = 'pe-asm-temp-apt.csv'
#ext_drive = '/opt/vs/asm'

out_file = 'pe-asm-features-vs251.csv'
temp_file = 'pe-asm-temp-vs251.csv'
ext_drive = '/opt/vs/train1asm/'
tfiles = os.listdir(ext_drive)

quart = len(tfiles)/4
train1 = tfiles[:quart]
train2 = tfiles[quart:(2*quart)]
train3 = tfiles[(2*quart):(3*quart)]
train4 = tfiles[(3*quart):]

mp1 = Multi_Params(out_file, temp_file, ext_drive, train1)
mp2 = Multi_Params(out_file, temp_file, ext_drive, train2)
mp3 = Multi_Params(out_file, temp_file, ext_drive, train3)
mp4 = Multi_Params(out_file, temp_file, ext_drive, train4)

trains = [mp1, mp2, mp3, mp4]
p = Pool(4)
p.map(extract_asm_features, trains)


combine_asm_files(out_file, temp_file)

# End of Script
    
