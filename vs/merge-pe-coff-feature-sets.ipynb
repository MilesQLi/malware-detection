{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: move all the merge code from model-selection-pe-coff.ipynb\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. VirusShare 251 Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: move this merging stuff to merge-feature-sets-pe-coff.ipynb\n",
    "# it is making the notebook too long.\n",
    "\n",
    "# Merge all the vs251 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "#\n",
    "# NOTE: keep function count features and ASM/Binary images separate, train on different models.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs251.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs251.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs251.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs251-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs251.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs251.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs251.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs251.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs251.csv') # Select only scalar columns.\n",
    "sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs251.csv')\n",
    "sorted_packer_id_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: the file name problem has been fixed now, do not use get_training_data()\n",
    "\n",
    "def get_training_data(sorted_train_features_df, sorted_train_labels_df, train_labels_file_out):\n",
    "    \n",
    "    X = sorted_train_features_df.iloc[:,1:]\n",
    "    ylabels = sorted_train_labels_df.iloc[:,4]\n",
    "    # not necessary, labels start at zero. ylabels = ylabels - 1 \n",
    "    sorted_sample_names = sorted_train_features_df.loc[:,'file_name']\n",
    "    \n",
    "    # Now get the labels of the PE malware samples from the label set.\n",
    "    counter = 0\n",
    "    y = []\n",
    "    #train_names = sorted_train_labels['family_label']\n",
    "    for fname in sorted_sample_names:\n",
    "        counter += 1\n",
    "        \n",
    "        # Have a slight problem with the file_names in asm feature sets,\n",
    "        # they still have .pe on the end.\n",
    "        idx = fname.find('.pe')\n",
    "        if idx > 0:\n",
    "            fname = fname[:idx]\n",
    "            \n",
    "        if counter % 100 == 1:\n",
    "            print(\"Appending {:d} -> {:s}\".format(counter, fname))\n",
    "        for idx, fname2 in enumerate(sorted_train_labels['file_name']):\n",
    "            if (fname2 == fname):\n",
    "                y.append(sorted_train_labels.iloc[idx, 4]) # Append the family class label.\n",
    "                break\n",
    "    \n",
    "    ###############################\n",
    "    # Write out the PE/COFF sample train labels for later use and validation.\n",
    "    fop = open(train_labels_file_out, 'w')\n",
    "    fop.writelines(\"\\n\".join(str(x) for x in y))\n",
    "    fop.close()\n",
    "    ###############################\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = combined_train_features.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()\n",
    "\n",
    "\n",
    "combined_train_features.to_csv('data/combined-pe-features-vs251.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VirusShare 252 PE/COFF Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge all the vs252 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs251.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs252.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs252.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs252-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs252.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs252.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs252.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs252.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs252.csv') # Select only scalar columns.\n",
    "# BROKEN:\n",
    "#sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs252.csv')\n",
    "#sorted_function_count_features = pd.read_csv('data/sorted-pe-function-counts-10percent-vs252.csv')\n",
    "\n",
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "#combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_features.to_csv('data/combined-pe-features-vs252.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEPRECATED: do no use get_training_data() now, problem has been fixed.\n",
    "X,y = get_training_data(sorted_asm_features_fixed, sorted_train_labels, 'data/sorted-pe-coff-train-labels-vs252.csv')\n",
    "print(\"Length of y: {:d}\".format(len(y)))\n",
    "print(\"Shape of X: {:d} {:d}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = get_training_data(combined_train_features, sorted_train_labels, 'data/sorted-pe-coff-train-labels-vs252.csv')\n",
    "print(\"Length of y: {:d}\".format(len(y)))\n",
    "print(\"Shape of X: {:d} {:d}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. VirusShare 263 PE/COFF Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>edx</th>\n",
       "      <th>esi</th>\n",
       "      <th>es</th>\n",
       "      <th>fs</th>\n",
       "      <th>ds</th>\n",
       "      <th>ss</th>\n",
       "      <th>gs</th>\n",
       "      <th>cs</th>\n",
       "      <th>ah</th>\n",
       "      <th>...</th>\n",
       "      <th>sidt</th>\n",
       "      <th>stc</th>\n",
       "      <th>std</th>\n",
       "      <th>sti</th>\n",
       "      <th>stos</th>\n",
       "      <th>sub</th>\n",
       "      <th>test</th>\n",
       "      <th>wait</th>\n",
       "      <th>xchg</th>\n",
       "      <th>xor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002b2f621ea5786be03bf4153532dce</td>\n",
       "      <td>52</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000401419eccde59975c713cfadc974c</td>\n",
       "      <td>4378</td>\n",
       "      <td>3246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>649</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004824a60ff9fe1fb30d669a5baa627</td>\n",
       "      <td>4374</td>\n",
       "      <td>3295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>653</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006d2cd674c8501ffe59dae330ffcb5</td>\n",
       "      <td>2100</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007893715059c51a92d3ce2b10d9cf5</td>\n",
       "      <td>163</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name   edx   esi  es  fs  ds  ss  gs  cs  ah  \\\n",
       "0  0002b2f621ea5786be03bf4153532dce    52   490   0   0   0   0   0   0   4   \n",
       "1  000401419eccde59975c713cfadc974c  4378  3246   1   0   0   0   0   0  34   \n",
       "2  0004824a60ff9fe1fb30d669a5baa627  4374  3295   1   0   0   0   0   0  34   \n",
       "3  0006d2cd674c8501ffe59dae330ffcb5  2100   959   0   0   0   0   0   0   0   \n",
       "4  0007893715059c51a92d3ce2b10d9cf5   163   180   0   0   0   0   0   0  31   \n",
       "\n",
       "   ...   sidt  stc  std  sti  stos  sub  test  wait  xchg   xor  \n",
       "0  ...      0    0    0    0     0   47   118     0     0   129  \n",
       "1  ...      0    0    1    0     0  343   649    88    42  1031  \n",
       "2  ...      0    0    1    0     0  343   653    88    42  1032  \n",
       "3  ...      0    0    1    0     0  154   307     2     6   472  \n",
       "4  ...      0    0    0    0     0   73    86     0    29    34  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vs263 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs251.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs263.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs263.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs263-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs263.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs263.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs263.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs263.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs263.csv') # Select only scalar columns.\n",
    "sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs263.csv')\n",
    "# Adding function counts makes the csv file too big for github,\n",
    "# model separately \n",
    "#sorted_function_count_features = pd.read_csv('data/sorted-pe-function-counts-10percent-vs263.csv')\n",
    "\n",
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = get_training_data(sorted_asm_features_fixed, sorted_train_labels, 'data/sorted-pe-coff-train-labels-vs263.csv')\n",
    "print(\"Length of y: {:d}\".format(len(y)))\n",
    "print(\"Shape of X: {:d} {:d}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002b2f621ea5786be03bf4153532dce</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000401419eccde59975c713cfadc974c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00042f23bc15b89d9c6a7bde0e316f8b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004824a60ff9fe1fb30d669a5baa627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004c49071481789f1c8c80656638497</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name  file_id\n",
       "0  0002b2f621ea5786be03bf4153532dce        5\n",
       "1  000401419eccde59975c713cfadc974c        1\n",
       "2  00042f23bc15b89d9c6a7bde0e316f8b        1\n",
       "3  0004824a60ff9fe1fb30d669a5baa627        1\n",
       "4  0004c49071481789f1c8c80656638497       13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>packer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002b2f621ea5786be03bf4153532dce</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000401419eccde59975c713cfadc974c</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00042f23bc15b89d9c6a7bde0e316f8b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004824a60ff9fe1fb30d669a5baa627</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004c49071481789f1c8c80656638497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name  packer_id\n",
       "0  0002b2f621ea5786be03bf4153532dce          0\n",
       "1  000401419eccde59975c713cfadc974c        317\n",
       "2  00042f23bc15b89d9c6a7bde0e316f8b          0\n",
       "3  0004824a60ff9fe1fb30d669a5baa627        317\n",
       "4  0004c49071481789f1c8c80656638497          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>percentage</th>\n",
       "      <th>trid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002b2f621ea5786be03bf4153532dce</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000401419eccde59975c713cfadc974c</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00042f23bc15b89d9c6a7bde0e316f8b</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004824a60ff9fe1fb30d669a5baa627</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004c49071481789f1c8c80656638497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name  percentage  trid_id\n",
       "0  0002b2f621ea5786be03bf4153532dce         7.4        1\n",
       "1  000401419eccde59975c713cfadc974c         5.4        4\n",
       "2  00042f23bc15b89d9c6a7bde0e316f8b         7.4        1\n",
       "3  0004824a60ff9fe1fb30d669a5baa627         5.4        4\n",
       "4  0004c49071481789f1c8c80656638497         0.0        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>edx</th>\n",
       "      <th>esi</th>\n",
       "      <th>es</th>\n",
       "      <th>fs</th>\n",
       "      <th>ds</th>\n",
       "      <th>ss</th>\n",
       "      <th>gs</th>\n",
       "      <th>cs</th>\n",
       "      <th>ah</th>\n",
       "      <th>...</th>\n",
       "      <th>vertex_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>delta_max</th>\n",
       "      <th>density</th>\n",
       "      <th>entropy</th>\n",
       "      <th>file_size</th>\n",
       "      <th>file_id</th>\n",
       "      <th>percentage</th>\n",
       "      <th>trid_id</th>\n",
       "      <th>packer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002b2f621ea5786be03bf4153532dce</td>\n",
       "      <td>52</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>518</td>\n",
       "      <td>74</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.684706</td>\n",
       "      <td>81812</td>\n",
       "      <td>5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000401419eccde59975c713cfadc974c</td>\n",
       "      <td>4378</td>\n",
       "      <td>3246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1593</td>\n",
       "      <td>3310</td>\n",
       "      <td>56</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.800788</td>\n",
       "      <td>137131</td>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004824a60ff9fe1fb30d669a5baa627</td>\n",
       "      <td>4374</td>\n",
       "      <td>3295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1593</td>\n",
       "      <td>3325</td>\n",
       "      <td>56</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.802050</td>\n",
       "      <td>137630</td>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006d2cd674c8501ffe59dae330ffcb5</td>\n",
       "      <td>2100</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>717</td>\n",
       "      <td>2167</td>\n",
       "      <td>285</td>\n",
       "      <td>0.049634</td>\n",
       "      <td>0.762935</td>\n",
       "      <td>83819</td>\n",
       "      <td>1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007893715059c51a92d3ce2b10d9cf5</td>\n",
       "      <td>163</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>795</td>\n",
       "      <td>1193</td>\n",
       "      <td>355</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>0.812079</td>\n",
       "      <td>120832</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name   edx   esi  es  fs  ds  ss  gs  cs  ah  \\\n",
       "0  0002b2f621ea5786be03bf4153532dce    52   490   0   0   0   0   0   0   4   \n",
       "1  000401419eccde59975c713cfadc974c  4378  3246   1   0   0   0   0   0  34   \n",
       "2  0004824a60ff9fe1fb30d669a5baa627  4374  3295   1   0   0   0   0   0  34   \n",
       "3  0006d2cd674c8501ffe59dae330ffcb5  2100   959   0   0   0   0   0   0   0   \n",
       "4  0007893715059c51a92d3ce2b10d9cf5   163   180   0   0   0   0   0   0  31   \n",
       "\n",
       "     ...      vertex_count  edge_count  delta_max   density   entropy  \\\n",
       "0    ...               365         518         74  0.234283  0.684706   \n",
       "1    ...              1593        3310         56  0.006680  0.800788   \n",
       "2    ...              1593        3325         56  0.006710  0.802050   \n",
       "3    ...               717        2167        285  0.049634  0.762935   \n",
       "4    ...               795        1193        355  0.052839  0.812079   \n",
       "\n",
       "   file_size  file_id  percentage  trid_id  packer_id  \n",
       "0      81812        5         7.4        1          0  \n",
       "1     137131        1         5.4        4        317  \n",
       "2     137630        1         5.4        4        317  \n",
       "3      83819        1         8.3       13          0  \n",
       "4     120832        1         3.5       13          0  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = combined_train_features.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_features.to_csv('data/combined-pe-features-vs263.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VirusShare 264 PE/COF Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vs264 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs264.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs264.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs264.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs264-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs264.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs264.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs264.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs264.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs264.csv') # Select only scalar columns.\n",
    "\n",
    "# BROKEN: need to re-generate the feature sets.\n",
    "#sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs264.csv')\n",
    "#sorted_function_count_features = pd.read_csv('data/sorted-pe-function-counts-10percent-vs264.csv')\n",
    "\n",
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "#combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_features.to_csv('data/combined-pe-features-vs264.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
