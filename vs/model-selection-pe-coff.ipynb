{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Selection.\n",
    "    - XGBoost\n",
    "    - LightGBM (Microsoft)\n",
    "    - CNTK (Microsoft)\n",
    "    - Leaf (https://github.com/autumnai/leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score, KFold, train_test_split\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "%pylab inline\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cv(X,y, clf):\n",
    "\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=10,shuffle=True)\n",
    "    y_prob = np.zeros((len(y),9))\n",
    "    y_pred = np.zeros(len(y))\n",
    "    \n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        print(test_index, train_index)\n",
    "        X_train = X.loc[train_index,:]\n",
    "        X_test = X.loc[test_index,:]\n",
    "        y_train = y[train_index]\n",
    "\n",
    "        clf.fit(X_train, y_train.flatten()) # use flatten to get rid of data conversion warnings\n",
    "        \n",
    "        y_prob[test_index] = clf.predict_proba(X_test)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        #print(clf.get_params())\n",
    "    \n",
    "    return y_prob, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs251.csv')\n",
    "sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs251.csv')\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs251.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs251.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs251.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs251.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs251.csv') # Select only scalar columns.\n",
    "sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs251.csv')\n",
    "sorted_asm_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign asm data to X,y for brevity, then split the dataset in two equal parts.\n",
    "#X = combined_train_data.iloc[:,1:]\n",
    "#y = np.array(sorted_train_labels.iloc[:,1])\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.xlabel(\"EDX Register\")\n",
    "plt.ylabel(\"Malware Class\")\n",
    "xa = np.array(X['edx'])\n",
    "xb = np.array(X['esi'])\n",
    "ya = np.array(y)\n",
    "plt.scatter(xa,ya,c=ya,cmap='brg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = combined_train_data.iloc[:,1:]\n",
    "ylabels = sorted_train_labels.iloc[:,1:]\n",
    "y = np.array(ylabels - 1)\n",
    "y = y.flatten()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgclf = xgb.XGBClassifier(objective=\"multi:softprob\", nthread=4)\n",
    "\n",
    "params     = {\"n_estimators\": [1000, 2000],\n",
    "              \"max_depth\": [5, 10],\n",
    "              \"learning_rate\": [0.1, 0.09]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xgclf, param_grid=params)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"XGBoost Classifier - GridSearchCV:\")\n",
    "print(\" \")\n",
    "print(\"Best parameters set found on training set:\")\n",
    "print(\" \")\n",
    "print(grid_search.best_params_)\n",
    "print(\" \")\n",
    "#print(\"Grid scores on training set:\")\n",
    "#print(\" \")\n",
    "#report(grid_search.grid_scores_)\n",
    "#print(\" \")\n",
    "print(\"Classification report:\")\n",
    "print(\"GridSearchCV took {:.2f} seconds.\".format((time() - start)))\n",
    "print(\" \")\n",
    "y_pred = grid_search.predict(X)\n",
    "print(classification_report(y, y_pred))\n",
    "print(\" \")\n",
    "y_prob = grid_search.predict_proba(X)\n",
    "print(\"logloss = {:.3f}\".format(log_loss(y, y_prob)))\n",
    "print(\"score = {:.3f}\".format(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
