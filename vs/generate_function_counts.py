# generate_function_counts.py
#
# Read a bunch of call graph files in GraphViz format and generate function count
# feature sets in CSV format.
#
# Input : Call graph files in GraphViz format.
#         GraphViz directed graph format:
#
#            digraph graph_name {
#                node_name1 -> { node_name2 ; node_name3 ; .... }
#                .
#                .
#                .
#                node_nameX -> { node_nameY ; node_nameZ ; .... }
#            }
# 
#
# Output: all-reduced-function-counts.csv
#         row format = [file_name, [list of function names]...]
#
#         all-reduced-function-column-names-singleline.txt
#         all-reduced-function-column-names-multiline.txt
#         (lists of function names extracted from the call graphs to be used as column names for the feature sets)
#
# Author: Derek Chadwick
# Date  : 14/11/2016
#
# TODO: optimise and many many things

import numpy as np
import pandas as pd
import graph as gra # http://www.python-course.eu/graphs_python.php
import os
from csv import writer
from multiprocessing import Pool
import re







def generate_function_counts(call_graph_file):
    # Generate function counts from graph files of the ASM malware samples.
    
    counter = 0
    error_count = 0
    
    #fapi = open("data/APIs.txt")
    #defined_apis = fapi.readlines()
    #defined_apis = defined_apis[0].split(',')
    #fapi.close()
    
    colf = open('data/all-reduced-function-column-names.csv', 'r')
    all_column_names = []
    column_lines = colf.readlines()
    for line in column_lines:
        all_column_names += line.split(',')
    col_names_len = len(all_column_names)
    colf.close()
    print("Column Names: {:d}".format(col_names_len))
    
    pid = os.getpid()
    print('Process id: {:d}'.format(pid))
    feature_file_name = 'data/' + str(pid) + '-call-graph-reduced-function_counts.csv'  
    print('Call graph function counts file: {:s}'.format(feature_file_name))
    feature_file = open(feature_file_name, 'w')
    fw = writer(feature_file)
    
    call_graph_function_features = []
    
    with open(call_graph_file, 'r', errors='ignore') as cfg:
        for line in cfg:
            
            if line.startswith(' }'):
                continue
                
            if line.startswith('digraph'):
                tokens = line.split()
                graph_name = tokens[1]
                graph_names.append(graph_name)
                continue
                
            line.rstrip('\r\n')  # get rid of newlines they are annoying.
            # get rid of all these things they are annoying.
            line = line.replace(';',' ').replace('{',' ').replace('}',' ').replace('->',' ').replace('\'',' ').replace('\"',' ')
            parts = line.split() # tokenize graph line
            
            graph_name = parts[0]
            parts = parts[1:]
            function_dict = {}
            
            # now generate the function counts for this call graph
            
            for func in parts:
                # lets try to reduce the vast number of functions.
                if func.startswith('sub') or func.startswith('loc') or func.startswith('unk'):
                    func = func[:5] 
                elif func.startswith('eax+') or func.startswith('ebx+') or func.startswith('ecx+') or func.startswith('edx+'):
                    func = func[:5]
                elif func.startswith('edi+') or func.startswith('esi+'):
                    func = func[:5]
                elif func.startswith('byte_') or func.startswith('word_') or func.startswith('off_'):
                    func = func[:5]
                elif func.startswith('_'): 
                    func = func[:5]
                
                if len(func) > 16:
                    func = func[:16]

                if (func in function_dict):
                    function_dict[func] += 1
                else:
                    function_dict[func] = 1
            
            # now generate the output row for this call graph

            function_counts = [0] * col_names_len # zero everything because this is a sparse matrix
            for func in function_dict:
                for idx, cname in enumerate(all_column_names):
                    if func == cname:
                        function_counts[idx] = function_dict[func]
                        break
                
            call_graph_function_features.append([graph_name] + function_counts)
            
            # Print progress and write out rows
            counter += 1
            if ((counter + 1) % 100) == 0:
                print("{:d} Graph: {:s} Count: {:d}".format(pid, graph_name, counter))
                fw.writerows(call_graph_function_features)
                call_graph_function_features = []
                
        # Write remaining files
        if len(call_graph_function_features) > 0:
            fw.writerows(call_graph_function_features)
            call_graph_function_features = []  
    
    feature_file.close()
    
    print("Completed processing {:d} graphs.".format(counter))
    
    return



# Start of script.

#TODO: parse command line options for input/output file names.

ext_drive = '/opt/vs/'
sample_set_id = 'vs251'

pecallgraphs = re.compile('\d{3,5}-pe-call-graphs-' + sample_set_id +'.gv') # This is the PID prefix for each file.

file_list = os.listdir(ext_drive)
call_graph_files = []
column_name_files = []

counter = 0
for file_name in file_list:
    if pecallgraphs.match(file_name):
        call_graph_files.append(file_name)
        counter += 1
        column_name_file = 'data/reduced-column-names-' + sample_set_id + '-' + str(counter) + '.txt'
        column_name_files.append(column_name_file)
        print("Found call graph file: {:s}".format(file_name))
        print("Column name file: {:s}".format(column_name_file))


for idx, call_graph_file_name in enumerate(call_graph_files):
    print("Doing column names: {:s} - {:s}".format(call_graph_file_name, column_name_files[idx]))
    generate_function_counts('/opt/vs/' + call_graph_file_name, column_name_files[idx])



# Now do the function counting.


              
              

# End of Script








