# Generate packer id values for PE files.
#
# Inputs: packer-id.csv (scalar lables for PE packer types.)
#         userdb-sans.txt (PEid.exe PE packer database.)
#
# Output: xxxx-sorted-packer-id-features.csv ( 4 x feature files )
#         row format = [malware_name, packer_name, packer_label]
#
# TODO: need a function to combine the four feature files into one csv file.
#
# Author: Derek Chadwick
# Date  : 04/08/2016



from multiprocessing import Pool
import os
import peutils
import pefile
import sys
import re


def load_packer_id_map():
    # Load the packer ID scalar labels and create a map. There are a lot of duplicate names so the total is less than
    # the number of packers listed in the signature db.
    packer_id_map = {}

    counter = 0
    fip = open('data/packer-id.csv','r')
    in_lines = fip.readlines()
    for idx in range(1,len(in_lines)):
        tokens = in_lines[idx].split(',')
        packer_name = tokens[0]
        if packer_name not in packer_id_map.keys():
            packer_id_map[packer_name] = int(tokens[1])
            counter += 1

    fip.close()
    print('Completed {:d} packer IDs.'.format(counter))
    
    return packer_id_map


def generate_sample_packer_id(file_list):
    # Lookup the scalar packer ID for each sample.
    pid = os.getpid()
    file_name = "data/" + str(pid) + "-sorted-packer-id-features.csv"
    fop = open(file_name,'w')
    fop.write('file_name,'+'packer_type,'+'label\n')
    out_lines = []
    packer_id_map = load_packer_id_map()
    signatures = peutils.SignatureDatabase('data/userdb-sans.txt')
    non_pe_counter = 0
    pe_file_counter = 0
    signat = 'unknown'
    
    for idx, file_name in enumerate(file_list):
        try:
            pe = pefile.PE(ext_drive + file_name, fast_load=True)
            pe_file_counter += 1
            #matches = signatures.match_all(pe, ep_only = True)
            matches = signatures.match(pe, ep_only = True)
            if matches == None:
                signat = ",unknown,0\n"
                row = file_name + signat
            else:
                signat = matches[0]
                if (signat in packer_id_map.keys()):
                    packer_id = packer_id_map[signat]
                else:
                    packer_id = 0
                #signat = ",".join(str(e) for e in matches)
                tokens = file_name.split('_') # remove the Virusshare_  prefix of the filename.
                row = tokens[1] + "," + signat + "," + str(packer_id) + "\n"

            out_lines.append(row)

            pe.close()        

        except:
            non_pe_counter += 1
            signat = ",nonpe,0\n"
            out_lines.append(file_name + signat)


        if (idx % 1000) == 0: # print progress
            fop.writelines(out_lines)
            out_lines = []
            print('{:s} - {:s} - {:d} - {:s}'.format(str(pid),file_name,idx,signat))


    if len(out_lines) > 0:
        fop.writelines(out_lines)
        out_lines = []

    fop.close()

    print('{:s} - Completed {:d} non PE files and {:d} PE files.'.format(str(pid), non_pe_counter, pe_file_counter))
    



def start_packer_id_generation_threads():
    ext_drive = '/opt/vs/train/'

    tfiles = os.listdir(ext_drive)
    quart = len(tfiles)/4
    train1 = tfiles[:quart]
    train2 = tfiles[quart:(2*quart)]
    train3 = tfiles[(2*quart):(3*quart)]
    train4 = tfiles[(3*quart):]
    print len(tfiles), quart, (len(train1)+len(train2)+len(train3)+len(train4))
    trains = [train1, train2, train3, train4]
    p = Pool(4)
    p.map(generate_sample_packer_id, trains)


    
def combine_packer_id_files(file_list):
    # TODO: function to combine the four packer id files in one file
    # 1. list data directory
    # 2. For each file in file list that matches (\d\d\d\d-packer-id-features.csv)
    # 3. Load into a dataframe and trim the filenames if necessary (should remove VirusShare_  prefix).
    # 4. Concatenate the four dataframes.
    # 5. Sort and write to data/sorted-packer-id-features.csv
    
    
    
def sort_and_save_packer_id_features():
    # Now sort the packer id features by filename
    # TODO: need a function to combine the four packer id files in one file
    packers = pd.read_csv('data/packer-id-features.csv')
    
    # trim the file_names and sort
    counter = 0
    for file_name in packers['file_name']:
        tokens = file_name.split('_')
        packers.iloc[counter,0] = tokens[1]
        counter += 1
        if (counter % 1000) == 0:
            print('{:s}'.format(file_name))
            
    # DataFrame.sort() is deprecated, but using an old version of pandas, does not have sort_values()!!!
    sorted_packers = packers.sort('file_name')
    sorted_packers.head(20)            
            
    sorted_packers.to_csv('data/sorted-packer-id-features.csv', index=False)
        