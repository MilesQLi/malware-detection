{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Extraction of Features\n",
    "    Features sets will consist of:\n",
    "    - Entropy and file size from packed binaries.\n",
    "    - Entropy and file size from unpacked binaries.\n",
    "    - ASM features from disassembled unpacked binaries.\n",
    "    - Call Graph Features.\n",
    "    - Sample Statistics.\n",
    "    - PE packer type.\n",
    "    - Behavioural features from Cuckoo Sandbox reports.\n",
    "    - Memory features from Volatility reports.\n",
    "    \n",
    "    Training labels will be generated from ClamAV and VirusTotal.com reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os\n",
    "from csv import writer\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.misc\n",
    "import array\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext_drive = '/opt/vs/'\n",
    "tfiles = os.listdir(ext_drive + \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Generate Entropy and File Size of Packed Binaries and Non-Binary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Shannon's Entropy, https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "\n",
    "def calculate_entropy(byte_counts, total):\n",
    "    \n",
    "    entropy = 0.0\n",
    "\n",
    "    for count in byte_counts:\n",
    "        # If no bytes of this value were seen in the value, it doesn't affect\n",
    "        # the entropy of the file.\n",
    "        if count == 0:\n",
    "            continue\n",
    "        # p is the probability of seeing this byte in the file, as a floating-point number\n",
    "        p = 1.0 * count / total\n",
    "        entropy -= p * math.log(p, 256)\n",
    "    \n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entropy_counter(byte_code):\n",
    "    \n",
    "    byte_counts = [0] * 256\n",
    "    code_length = len(byte_code)\n",
    "    \n",
    "    for i in range(len(byte_code)):\n",
    "        byte_counts[int(byte_code[i])] += 1\n",
    "        \n",
    "    entropy = calculate_entropy(byte_counts, code_length)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "#textchars = bytearray({7,8,9,10,12,13,27} | set(range(0x20, 0x100)) - {0x7f})\n",
    "#is_binary_string = lambda bytes: bool(bytes.translate(None, textchars))\n",
    "\n",
    "# feature extraction for the binary files\n",
    "\n",
    "def extract_binary_features(tfiles):\n",
    "    #byte_files = [i for i in tfiles if '.bytes' in i]\n",
    "    ftot = len(tfiles)\n",
    "    \n",
    "    pid = os.getpid()\n",
    "    print('Process id:', pid)\n",
    "    feature_file = 'data/' + str(pid) + '-malware-features-bin.csv' # entropy, file size, ngrams...   \n",
    "    print('feature file:', feature_file)\n",
    "    \n",
    "    feature_counts = []\n",
    "    with open(feature_file, 'w') as f:\n",
    "        # Write the column names for the csv file\n",
    "        fw = writer(f)\n",
    "        colnames = ['file_name'] + ['entropy'] + ['file_size']\n",
    "        fw.writerow(colnames)\n",
    "        \n",
    "        # Now iterate through the file list and extract the features from each file.\n",
    "        for idx, fname in enumerate(tfiles):\n",
    "            fasm = open(ext_drive + fname, 'rb')\n",
    "            filesize = os.path.getsize(ext_drive + fname)\n",
    "            in_bytes = fasm.read()\n",
    "            \n",
    "            # TODO: Do ngram extraction\n",
    "            # First do entropy calculations and filesize\n",
    "            #print(\"Type = {:s}\").format(type(in_bytes))\n",
    "            in_bytes = bytearray(in_bytes)\n",
    "            #print(\"Type = {:s}\").format(type(in_bytes))\n",
    "            entropy = entropy_counter(in_bytes)\n",
    "            \n",
    "            count_vals = [entropy, filesize]\n",
    "            \n",
    "            feature_counts.append([fname[fname.find('_')+1:]] + count_vals)   \n",
    "            \n",
    "            fasm.close()\n",
    "            \n",
    "            # Print progress\n",
    "            if (idx+1) % 1000 == 0:\n",
    "                print(\"{:d} - {:d} of {:d} files processed.\".format(pid, idx + 1, ftot))\n",
    "                fw.writerows(feature_counts)\n",
    "                feature_counts = []\n",
    "                \n",
    "        # Write remaining files\n",
    "        if len(feature_counts) > 0:\n",
    "            fw.writerows(feature_counts)\n",
    "            feature_counts = []\n",
    "\n",
    "        print(\"Completed processing {:d} rows for feature file {:s}\".format(ftot,feature_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Process id:', 1920)\n",
      "('feature file:', 'data/1920-malware-features-bin.csv')\n",
      "(1920, 1000, 'of', 65536, 'files processed.')\n",
      "(1920, 2000, 'of', 65536, 'files processed.')"
     ]
    }
   ],
   "source": [
    "ext_drive = '/media/derek/TOSHIBA EXT/kali-acer/project/temp/train2/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "extract_binary_features(tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "# Now divide the train files into four groups for multiprocessing\n",
    "ext_drive = '/media/derek/TOSHIBA EXT/kali-acer/project/temp/train2/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "quart = len(tfiles)/4\n",
    "train1 = tfiles[:quart]\n",
    "train2 = tfiles[quart:(2*quart)]\n",
    "train3 = tfiles[(2*quart):(3*quart)]\n",
    "train4 = tfiles[(3*quart):]\n",
    "print len(tfiles), quart, (len(train1)+len(train2)+len(train3)+len(train4))\n",
    "trains = [train1, train2, train3, train4]\n",
    "p = Pool(4)\n",
    "p.map(extract_binary_features, trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Entropy and File Size of Unpacked Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
