{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: move all the merge code from model-selection-pe-coff.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. VirusShare 251 Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: move this merging stuff to merge-feature-sets-pe-coff.ipynb\n",
    "# it is making the notebook too long.\n",
    "\n",
    "# Merge all the vs251 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs251.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs251.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs251.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs251-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs251.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs251.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs251.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs251.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs251.csv') # Select only scalar columns.\n",
    "sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs251.csv')\n",
    "sorted_packer_id_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: the file name problem has been fixed now, do not use get_training_data()\n",
    "\n",
    "def get_training_data(sorted_train_features_df, sorted_train_labels_df, train_labels_file_out):\n",
    "    \n",
    "    X = sorted_train_features_df.iloc[:,1:]\n",
    "    ylabels = sorted_train_labels_df.iloc[:,4]\n",
    "    # not necessary, labels start at zero. ylabels = ylabels - 1 \n",
    "    sorted_sample_names = sorted_train_features_df.loc[:,'file_name']\n",
    "    \n",
    "    # Now get the labels of the PE malware samples from the label set.\n",
    "    counter = 0\n",
    "    y = []\n",
    "    #train_names = sorted_train_labels['family_label']\n",
    "    for fname in sorted_sample_names:\n",
    "        counter += 1\n",
    "        \n",
    "        # Have a slight problem with the file_names in asm feature sets,\n",
    "        # they still have .pe on the end.\n",
    "        idx = fname.find('.pe')\n",
    "        if idx > 0:\n",
    "            fname = fname[:idx]\n",
    "            \n",
    "        if counter % 100 == 1:\n",
    "            print(\"Appending {:d} -> {:s}\".format(counter, fname))\n",
    "        for idx, fname2 in enumerate(sorted_train_labels['file_name']):\n",
    "            if (fname2 == fname):\n",
    "                y.append(sorted_train_labels.iloc[idx, 4]) # Append the family class label.\n",
    "                break\n",
    "    \n",
    "    ###############################\n",
    "    # Write out the PE/COFF sample train labels for later use and validation.\n",
    "    fop = open(train_labels_file_out, 'w')\n",
    "    fop.writelines(\"\\n\".join(str(x) for x in y))\n",
    "    fop.close()\n",
    "    ###############################\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = combined_train_features.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()\n",
    "\n",
    "\n",
    "combined_train_features.to_csv('data/combined-pe-features-vs251.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VirusShare 252 PE/COFF Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge all the vs252 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs251.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs252.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs252.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs252-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs252.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs252.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs252.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs252.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs252.csv') # Select only scalar columns.\n",
    "# BROKEN:\n",
    "#sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs252.csv')\n",
    "#sorted_function_count_features = pd.read_csv('data/sorted-pe-function-counts-10percent-vs252.csv')\n",
    "\n",
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "#combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_features.to_csv('data/combined-pe-features-vs252.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEPRECATED: do no use get_training_data() now, problem has been fixed.\n",
    "X,y = get_training_data(sorted_asm_features_fixed, sorted_train_labels, 'data/sorted-pe-coff-train-labels-vs252.csv')\n",
    "print(\"Length of y: {:d}\".format(len(y)))\n",
    "print(\"Shape of X: {:d} {:d}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = get_training_data(combined_train_features, sorted_train_labels, 'data/sorted-pe-coff-train-labels-vs252.csv')\n",
    "print(\"Length of y: {:d}\".format(len(y)))\n",
    "print(\"Shape of X: {:d} {:d}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. VirusShare 263 PE/COFF Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vs263 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs251.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs263.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs263.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs263-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs263.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs263.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs263.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs263.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs263.csv') # Select only scalar columns.\n",
    "\n",
    "# BROKEN: need to re-generate the feature sets.\n",
    "#sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs263.csv')\n",
    "#sorted_function_count_features = pd.read_csv('data/sorted-pe-function-counts-10percent-vs263.csv')\n",
    "\n",
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = get_training_data(sorted_asm_features_fixed, sorted_train_labels, 'data/sorted-pe-coff-train-labels-vs263.csv')\n",
    "print(\"Length of y: {:d}\".format(len(y)))\n",
    "print(\"Shape of X: {:d} {:d}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "#combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_features.to_csv('data/combined-pe-features-vs263.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VirusShare 264 PE/COF Feature Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vs264 Feature sets:\n",
    "# 1. PE ASM features.\n",
    "# 2. Entropy features.\n",
    "# 3. File ID features.\n",
    "# 4. Packer ID features.\n",
    "# 5. PE Call Graph features.\n",
    "# 6. Trid ID features.\n",
    "# 7. PE Header features.\n",
    "# 8. TODO: function count features.\n",
    "# 9. TODO: Binary or ASM images (RNN/CNN models).\n",
    "#\n",
    "# Final Combination: combine all PE/COFF features then use chi2 tests to \n",
    "# reduce to 10% best feature set ->\n",
    "#     all-combined-pe-features-10perc-vs264.csv\n",
    "\n",
    "sorted_train_labels = pd.read_csv('data/sorted-train-labels-vs264.csv')\n",
    "#sorted_asm_features = pd.read_csv('data/sorted-pe-asm-features-vs264.csv')\n",
    "sorted_asm_features_fixed = pd.read_csv('data/sorted-pe-asm-features-vs264-fixed.csv')\n",
    "\n",
    "sorted_entropy_features = pd.read_csv('data/sorted-entropy-features-vs264.csv')\n",
    "sorted_file_id_features = pd.read_csv('data/sorted-file-id-features-vs264.csv')\n",
    "sorted_packer_id_features = pd.read_csv('data/sorted-packer-id-features-vs264.csv')\n",
    "sorted_call_graph_features = pd.read_csv('data/sorted-pe-call-graph-features-vs264.csv')\n",
    "sorted_trid_id_features = pd.read_csv('data/sorted-trid-id-features-vs264.csv') # Select only scalar columns.\n",
    "\n",
    "# BROKEN: need to re-generate the feature sets.\n",
    "#sorted_header_features = pd.read_csv('data/sorted-pe-header-features-10percent-vs264.csv')\n",
    "#sorted_function_count_features = pd.read_csv('data/sorted-pe-function-counts-10percent-vs264.csv')\n",
    "\n",
    "sorted_asm_features_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileidfeatures = pd.DataFrame(sorted_file_id_features.iloc[:,[0,2]])\n",
    "fileidfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packeridfeatures = pd.DataFrame(sorted_packer_id_features.iloc[:,[0,2]])\n",
    "packeridfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trididfeatures = pd.DataFrame(sorted_trid_id_features.iloc[:,[0,2,3]])\n",
    "trididfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the feature sets, ensure we drop all the rows that are not in the PE/COFF sample set.\n",
    "# NOTE: use stream editor to fix ASM file_name field: echo 'as;dflkj;a.pe,123' | sed s/\\.pe//\n",
    "\n",
    "#combined_train_features = sorted_asm_features_fixed.merge(sorted_header_features, on='file_name', how='inner', suffixes=('_asm','_hd'))\n",
    "combined_train_features = sorted_asm_features_fixed.merge(sorted_call_graph_features, on='file_name', how='inner', suffixes=('_asm','_cg'))\n",
    "combined_train_features = combined_train_features.merge(sorted_entropy_features, on='file_name', how='inner', suffixes=('_asm','_ent'))\n",
    "combined_train_features = combined_train_features.merge(fileidfeatures, on='file_name', how='inner', suffixes=('_asm','_fid'))\n",
    "combined_train_features = combined_train_features.merge(trididfeatures, on='file_name', how='inner', suffixes=('_asm','_tid'))\n",
    "combined_train_features = combined_train_features.merge(packeridfeatures, on='file_name', how='inner', suffixes=('_asm','_pid'))\n",
    "\n",
    "combined_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_features.to_csv('data/combined-pe-features-vs264.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
