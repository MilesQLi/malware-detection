# generate_function_counts.py
#
# Read a bunch of call graph files in GraphViz format and generate function count
# feature sets in CSV format.
#
# Input : Call graph files in GraphViz format.
#         GraphViz directed graph format:
#
#            digraph graph_name {
#                node_name1 -> { node_name2 ; node_name3 ; .... }
#                .
#                .
#                .
#                node_nameX -> { node_nameY ; node_nameZ ; .... }
#            }
# 
#
# Output: all-reduced-function-counts.csv
#         row format = [file_name, [list of function names]...]
#
#         all-reduced-function-column-names-singleline.txt
#         all-reduced-function-column-names-multiline.txt
#         (lists of function names extracted from the call graphs to be used as column names for the feature sets)
#
# Author: Derek Chadwick
# Date  : 14/11/2016
#
# TODO: optimise and many many things

import numpy as np
import pandas as pd
import graph as gra # http://www.python-course.eu/graphs_python.php
import os
from csv import writer
from multiprocessing import Pool
import re







def generate_function_counts(call_graph_file, column_names_file, feature_file_name):
    # Generate function counts from graph files of the ASM malware samples.
    
    counter = 0
    error_count = 0
    graph_name = 'none'
    graph_counter = 0
    
    colf = open(column_names_file, 'r')
    all_column_names = []
    column_lines = colf.readlines()
    for line in column_lines:
        all_column_names += line.split(',')
    col_names_len = len(all_column_names)
    colf.close()
    print("Column Names: {:d}".format(col_names_len))
    
    pid = os.getpid()
    print('Process id: {:d}'.format(pid))  
    print('Call graph function counts file: {:s}'.format(feature_file_name))
    feature_file = open(feature_file_name, 'a')
    fw = writer(feature_file)
    fw.writerow(all_column_names)
    
    call_graph_function_features = []
    
    with open(call_graph_file, 'r') as cfg:
        for line in cfg:
            
            if line.startswith(' }'): # End of current graph, append the function counts to the feature list.
                call_graph_function_features.append([graph_name] + function_counts)
                continue
                
            if line.startswith('digraph'):
                function_counts = [0] * col_names_len # zero everything because this is a sparse matrix
                tokens = line.split()
                graph_name = tokens[1]
                graph_counter += 1
                continue
                
            line.rstrip('\r\n')  # get rid of newlines they are annoying.
            # get rid of all these things they are annoying.
            line = line.replace(';',' ').replace('{',' ').replace('}',' ').replace('->',' ').replace('\'',' ').replace('\"',' ')
            parts = line.split() # tokenize graph line
            
            function_dict = {}
            
            # now generate the function counts for this call graph
            
            for func in parts:
                # lets try to reduce the vast number of functions.
                if func.startswith('sub') or func.startswith('loc') or func.startswith('unk'):
                    func = func[:5] 
                elif func.startswith('eax+') or func.startswith('ebx+') or func.startswith('ecx+') or func.startswith('edx+'):
                    func = func[:5]
                elif func.startswith('edi+') or func.startswith('esi+'):
                    func = func[:5]
                elif func.startswith('byte_') or func.startswith('word_') or func.startswith('off_'):
                    func = func[:5]
                elif func.startswith('_'): 
                    func = func[:5]
                
                if len(func) > 16:
                    func = func[:16]

                if (func in function_dict):
                    function_dict[func] += 1
                else:
                    function_dict[func] = 1
            
            # now generate the output row for this call graph

            
            for func in function_dict:
                #indexof(func):
                for idx, cname in enumerate(all_column_names):
                    if func == cname:
                        function_counts[idx] = function_dict[func]
                        break
                
            
            
            # Print progress and write out rows
            counter += 1
            if ((counter + 1) % 10000) == 0:
                print("{:d} Graph: {:s} Graph Count: {:d} Line Count: {:d}".format(pid, graph_name, graph_counter, counter))
                fw.writerows(call_graph_function_features)
                call_graph_function_features = []
                
        # Write remaining files
        if len(call_graph_function_features) > 0:
            fw.writerows(call_graph_function_features)
            call_graph_function_features = []  
    
    feature_file.close()
    
    print("Completed processing {:d} graph lines.".format(counter))
    
    return



# Start of script.

#TODO: parse command line options for input/output file names.

ext_drive = '/opt/vs/'
sample_set_id = 'vs252'
#sample_set_id = 'apt'
feature_file_name = 'data/call-graph-reduced-function_counts-' + sample_set_id + '.csv'
column_name_file = 'data/all-column-names-single-line-' + sample_set_id + '.txt'

pecallgraphs = re.compile('\d{3,5}-pe-call-graphs-' + sample_set_id +'.gv') # This is the PID prefix for each file.

file_list = os.listdir(ext_drive)
call_graph_files = []

counter = 0
for file_name in file_list:
    if pecallgraphs.match(file_name):
        call_graph_files.append(file_name)
        counter += 1
        print("Found call graph file: {:s}".format(file_name))


for idx, call_graph_file_name in enumerate(call_graph_files):
    print("Doing  function counts: {:s}".format(call_graph_file_name))
    generate_function_counts('/opt/vs/' + call_graph_file_name, column_name_file, feature_file_name)


print("Completed function counts for sample set id: {:s}".format(sample_set_id))

# End of Script








